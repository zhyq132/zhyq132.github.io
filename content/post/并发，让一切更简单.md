---
title: "并发，让一切更简单"
date: 2017-06-26T16:23:55+08:00
tags: ["golang"]
author: "七哥"
categories: ["Golang"]
---

## 前言
- 翻译自[Concurrency made easy](https://dave.cheney.net/paste/concurrency-made-easy.pdf)

Good afternoon! It’s my pleasure to be here with you at the inaugural Gophercon Singapore.
This talk is "Concurrency made Easy”.

- 下午好，我很高兴在新加坡go开发者聚会开幕式上，和你们一起，我的演讲主题是“并发让世界更简单”

My name is David. I’m a software programmer and hardware enthusiast from Sydney, Australia.
If i’m honest, this slide is just here so keynote’s timer starts correctly

- 我叫大卫，是一名来自澳大利亚悉尼的软件开发者、硬件爱好者。如我所说属实，--------

For my talk, I want to continue the theme of concurrency that the previous speakers have touched upon.
As someone who has the privilege of talking with programmers who are considering adopting Go, I find that a common motivation amongst many is they want to take
advantage of the parallelism inherent in modern hardware.

- 在我的演讲里，我希望继续前一个演讲者谈及的主题：并发。作为一个有优先权跟“正考虑采用go的开发者”交谈的人，我发现了大多数这类型程序员有一个共同的动机：他们希望用到现代硬件中的固有并行性。


Similarly, in my self appointed role of developer advocate, when I meet people who’ve learnt Go, one of the more common thing they say after they have been writing Go
for a year or so are things like this:
Do either of these quotes resonate with you? Maybe a little bit?
If you learn Go formally from a book or training course, you might have noticed that the concurrency section is always one of the last you’ll cover. I know that this is true for my own training material.

- 类似地，在我自己指定的开发人员的角色中，当我遇到那些学过go的人，他们在写了一年之后说的一件更常见的事情是这样的:这两句话都能引起你的共鸣吗?也许一点?如果您从书本或培训课程中学到正式的知识，您可能已经注意到，并发性部分永远是您最后要讨论的内容之一。我知道这对我自己的训练材料来说是真的。

Clearly there is a disconnect between the concurrency primitives that the language oﬀers, and the expectations of many who come to Go for exactly those features. 
There is a dichotomy here; Go’s headline feature is our simple, lightweight concurrency model. As a product, our language almost sells itself on this on feature alone.
 But on the other hand there is a narrative that concurrency isn’t actually that easy to use, otherwise authors wouldn’t make it the last chapter in their book and we wouldn’t look back on our formative eﬀorts with regret.
 
 - 很显然，在“语言提供的原生并发特性”与“冲着这些特性而来使用go的用户的期望”之间，有了脱节。这里要二分的来看待这些：go的大力宣传的信息是“简单、轻量级的并发模型”，但是作为一个产品，我们的语言也总是按照这些特点来进行兜售（推广）。但是另一个方面来说，并发 通常并不是很容易使用，否则作者不会让并发作为教程的最后一章，而且我们也不会重新审视因为懊悔而形成的错误

And this is a shame, because I believe that not only is Go’s concurrency model one of the simplest available
 but the requirement for programmers to embrace the parallelism inherent in their hardware has never been more acute. 
So with this as a background, I’d like to spend my time today talking some ideas to make concurrency easier to use, not just for newcomers, but for all of us.

- 很遗憾，因为我相信那不是因为go的并发模型的问题，它是最简单的并发模型。但是对程序员来说，需要他们在大脑层面中理解并行特性的要求从来没有这么严格

Let’s start, at the obvious place, with talking about the go keyword.

- 让我们开始吧，在显而易见的地方，一起讨论go关键字


```
package main

import (
	fmt
	log
	net/http
)

func main() {
	http.HandleFunc(/, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, Hello, GopherCon SG) })

	go func() {
		if err := http.ListenAndServe(:8080, nil); err != nil {
			log.Fatal(err)
		}
	}()
	
	for {
	}
}
```
- 这是一个简单的web2.0的程序，又没有谁能告诉我他有什么问题？
问题在for{} 这里，for是一个死循环

for{} is going to block the main goroutine because it doesn’t do any IO, wait on a lock, send or receive on a channel, or otherwise communicate with the scheduler. 
As the runtime is mostly cooperatively scheduled, this program is going to spin fruitlessly on a single CPU, and may eventually end up live-locked.
How could we ﬁx this? Here’s one suggestion.

- for{} 会阻塞main-goroutine，因为不会做任何的IO、等待一个锁、发送或者接受一个channel管道、或者其他任何与调度进程的通信。由于runtime是一个协作的调度器，这个程度即将再单个cpu上进行无效的运转，可能最终会变成一个活锁。我们能对此做什么？这里有一个解决方法

```
package main

import (
	fmt
	log
	net/http
	runtime
)

func main() {
	http.HandleFunc(/, func(w http.ResponseWriter, r *http.Request) {
		fmt.Fprintln(w, Hello, GopherCon SG)
	})
	go func() {
		if err := http.ListenAndServe(:8080, nil); err != nil {
			log.Fatal(err)
		}
	}()
	for {
		runtime.Gosched()
	}
}
```
Don’t laugh, this is a common solution I see. It’s symptomatic of not understanding the underlying problem.
Now, if you’re a little more experienced with go, you might instead write something like this.

- 不要笑，这是我看到的一个普遍的解决方式，想出这个解决办法是因为没有理解潜在的问题。现在，如果你有一点儿go的经验，你有可能写出类似这样的代码。

```
package main

import (
	fmt
	log
	net/http
)

func main() {
	http.HandleFunc(/, func(w http.ResponseWriter, r *http.Request) {
		fmt.Fprintln(w, Hello, GopherCon SG)
	})
	go func() {
		if err := http.ListenAndServe(:8080, nil); err != nil {
			log.Fatal(err)
		}
	}()
	select {}
}
```
An empty select statement will block forever. This is a useful property because now we’re not spinning a whole CPU just to call runtime.GoSched(). 
However, as I said before, we’re only treating the symptom, not the cause.
I want to present to you another solution, one which has hopefully already occurred to you.

- 一个空的select代码块将永远的阻塞。这是一个有用的属性，因为这个时候我们不用空转整个cpu或者去调用runtime.GoSched()。不论怎么样，正如我之前所说，我们仅仅是在治疗症状，而不是本因。
我还想为你介绍一个解决方案，希望你们已经想到了
```
package main

import (
	fmt
	log
	net/http
)

func main() {

	http.HandleFunc(/, func(w http.ResponseWriter, r *http.Request) {
		fmt.Fprintln(w, Hello, GopherCon SG)
	})
	if err := http.ListenAndServe(:8080, nil); err != nil {
		log.Fatal(err)
	}
}
```
Rather than run ListenAndServe in a goroutine, leaving us with the problem of what to do with the main goroutine
Simply run ListenAndServe on the main grouting itself

- 不要运行ListenAndServe在协程里，留给我们的一个问题是怎么处理go的main主程。只在go 主程里运行ListenAndServe

So this is my ﬁrst suggestion:
If your goroutine cannot make progress until it gets the result from another, oftentimes it is simpler to just do the work yourself rather than to delegate it. 
This often coincides with eliminating a lot of state tracking and channel manipulation required to plumb a result back from a goroutine to its initiator.
I’ve chosen to make this my ﬁrst example, because compared to my next, it’s not only the shorter, but perhaps the more profound. Many Go programmers overuse goroutines, especially when they are starting out.

- 所以，这是我的第一个建议：如果你的go协成依赖从另一个go协程里得到结果才能执行，那么通常情况下还是让它自己做这个事情比较简单，而不是把它委派给别人。消除大量的状态跟踪、管道操作通常是相吻合的，发起者都需要从goroutine里获取结果。我选择让这段代码成为我的讲解示例，因为和我的下一个例子相比，它不仅仅更短、而且可能更深刻一点。许多go程序员过度使用了goroutines，尤其是刚刚接触go的程序员。

The previous example showed using a goroutine when one wasn’t really necessary.
But of course, this is Go, and one receives no points for only doing one thing at a time
Indeed there are many instances where you want to exploit the parallelism available in your hardware. And to do so, you must use gorotuines

- 前一个例子向我们展示了一个不必要的时候去使用goroutine的情况，但是当然，这是GO，同时只做一件事情是没有意义的。实际上，有许多实例需要利用你硬件中可用的“并行性”，这样一来，你必须使用goroutines。

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		sem <- 1
		go func() {
			defer func() {
				wg.Done()
				<-sem
			}()
			if err := fetch(repo); err != nil {
				errChan <- err
			}
		}()
	}
	wg.Wait()
	close(sem)
	close(errChan)
	return <-errChan
}
```
In this example, simpliﬁed from a prior version of gb-vendor, we’re attempting to fetch a set of dependencies from their remote repositories, in parallel.
I’ll give you a minute to look at this code. Does it look reasonable to you? Can anyone spot any problems with the restore function?
It turns out that there are several problems with this piece of code.

- 在这个例子中，是一个从gb-vendor早期版本中的简化，我们试图从远端仓库去并行的获取一组依赖。我会给你一分钟去看一下这段代码，对你来说它是合理的吗？有谁能指出restore方法的问题吗？事实证明，这段代码片段中，有几个问题

As a code reviewer my ﬁrst point of concern is the interaction between this section:

- 作为一个代码复查元，我的第一个关注点是这块代码的交互：
```
defer func() {
        wg.Done()
        <-sem
}()
```
and this section:
```
wg.Wait()
close(sem)
```
My question for you is, close(sem) happens after wg.Wait() therefore it also happens after wg.Done(), but not necessarily after <-sem — the close could occur before.
Could this cause a panic?

- 我的问题是，`close(sem)`在`wg.Wait()`后面发生，因此`close(sem)`也要在`wg.Done()`之后发生，但不是必须在`<-sem`操作之后，`close(sem)`可在`<-sem`之前。这会引起panic吗

As it happens, no it cannot cause a panic. 
Either <-sem happens before close(sem), in which case it drains a value from sem and then sem is marked closed, or close(sem) occurs ﬁrst, 
What does receiving from a closed channel return? the zero value
And when does it return? immediately
But you had to think about it to be sure. The logic is unnecessarily confusing.
If we simplify the defer statement and reorder the operations to get

- 当它执行时，不会引起一个panic。1，`<-sem`在`close(sem)`之前执行时，从channel中释放一个值，然后sem对应的channel被标记为closed；2，`close(sem)`限制性，从一个关闭的channel中能获得什么返回值？0值！`什么时候`返回？立即返回！！！但是你必须仔细的思考一下，这个逻辑引起了不必要的困惑。。。如果我们对defer方法块进行简化，并且语句进行重新排序。
```
func restore(repos []string) error {
	errChan := make(chan error, 1)        
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		sem <- 1                
		go func() {                        
			defer wg.Done()                        
			if err := fetch(repo); err != nil {
			    errChan <- err                        
			}                        
			<-sem                
		}()        
	}        
	wg.Wait()        
	close(sem)        
	close(errChan)        
	return <-errChan 
}
```
Now there is no question in which order the operations will occur. 
In this program we add to the wait group, then push a value onto the sem channel, raising the level of the semaphore. 
When each goroutine is done, the reverse occurs, we remove a value from the sem channel, lowering the semaphore, and then defer calls wg.Done as the ﬁnal operation, to indicate that the goroutine is done.
So my suggestion to you is

- 现在，提供操作的代码块，不会再有问题。在这个代码中，我们加入了wait group操作，然后往sem channel中推入一个值，提高了信号量的级别。当每一个go协程完成后，触发相反的操作：从sem中释放一个值，降低信号的水平，并且然后defer操作调用`wg.done`作为最后一个操作，指出go协程全部完成，所以我建议你这样做。

Always `release locks and semaphores in the reverse order to which you acquired them.`
At best, mixing the order of acquire and release generates confusing code which is difficult to reason about. 
At worst, mixing acquire and release leads to lock inversion and deadlocks.
- 总是`以相反的顺序释放锁和信号量`，在最好的代码里里，打乱捕获、释放的顺序会产生混淆，这就是为什么会感觉难以理解。在最坏的情况下，混合了捕获、释放导致锁反转和死锁。

Why close(sem) ?
Now that we’ve rearranged the program a little, we can ask another question. What is the reason for closing sem?
If a restaurant closes, it does not remove anyone seated at that time, it’s just an indication that the restaurant is not taking additional patrons.
Similarly, channels are not resources like ﬁles or network sockets; the close signal does not free a channel, it just marks that channel as no longer accepting new values
In our example nothing is waiting in a select or range loop for a close signal on sem, so we can remove the close(sem) call.
Closing a channel is a signal to its receivers that it is no longer accepting new data; nothing more, nothing less.
Closing a channel is not necessary to "free" a channel. You don’t need to close a channel to "clean up" its resources.
- 为什么要`close(sem)`？现在，我们重新排列了代码，我要问另一个问题了：要`close(sem)`的理由是什么。如果一个餐馆关门了，他不需要让每一个坐着的顾客离开，他仅仅只是表明餐馆不再让顾客进来了。。。一样的容易理解，channel不像file文件、网络socket等资源，这个关闭信号不会释放一个channel，他只是标记channel不会再写入了。在我们的示例中，select、range没有应用于一个关闭的channel，所以我们可以移除`close(sem)`的调用。关闭一个channel对接收者来说是一个信号，表明他不在写入新的数据，没有再多的意义。关闭一个channel不需要去释放一个channel，不必去清除channel的资源。
Speaking of semaphores, let’s look a bit closer at how sem is used.
- 当谈论信号量的时候，让我们看看sem是怎么使用的。

The role of sem is to make sure that at any one time, there is a cap on the number of fetch operations running. In this example, sem has a capacity of four.
But if you look closely, sem isn’t guaranteeing there are no more than four fetch operations running, it’s guaranteeing that there are no more than four goroutines running.
- sem作用是确认同一时间，同时进行fetch 的操作有一个上限，在这个例子中，sem的容量是4.但是如果你仔细看一下，sem不保证‘不超过四个’fetch操作在同时运行时，它仅仅是保证‘不超过四个’goroutine在同时运行。

```
for _, repo := range repos {
    sem <- 1                
    go func() {                        
        defer wg.Done()                        
        if err := fetch(repo); err != nil {
            errChan <- err                        
        }                        
        <-sem                
    }()        
}      
```
Assuming there are enough values in repos, each time through the loop we try to push the number 1 onto the sem channel, then we ﬁre oﬀ a fetch goroutine.
What happens when it’s the ﬁfth time through the loop? Most likely we’ll have four fetch goroutines running, or possibly those four goroutines won’t even have been scheduled to run yet，remember that the scheduler doesn’t give any guarantees if it will run a goroutine immediately, or schedule for later.
On the ﬁfth iteration the main loop is going to block trying to push a value onto sem. Rather than spawning len(repos) goroutines which coordinate amongst themselves for a semaphore, this loop will proceed at the rate that fetch invocations ﬁnish.
While it doesn’t matter in this example--restore blocks until all repos have been fetched—there are many situations where the calling code may expect the function scheduling its work to complete quickly and return, while the work occurs in the background.
- 假设，repos有足够多的值，每次开始循环时，我们往sem channel中推入一个值，紧接着我们发起一个go协程，那么当第五次开始循环的时候会发生什么。最可能的是我们有四个正在fetch的协程，或者有可能那四个协程还没有被调度器执行，记住，调度器不会承诺“立即或稍后运行go协程”。在主协程的第五次迭代循环，将会阻塞住不继续往sem中插入值，而不是同时发起‘len(repos)个’任由自身进行协调的协程。。循环会继续按照fetch操作完成的速率执行。当然，在这个例子中，继续阻塞直到所有的repos被fetch完成是无关紧要的，但是许多场景下，当任务在后台运行时，程序希望func快速的完成其任务并返回结果。
```
func restore(repos []string) error {
	errChan := make(chan error, 1)        
	sem := make(chan int, 4) // four jobs at once        
	var wg sync.WaitGroup        
	wg.Add(len(repos))        
	for _, repo := range repos {
		go func() {
			defer wg.Done()
			sem <- 1 
			if err := fetch(repo); err != nil {
				errChan <- err                        
			}                        
			<-sem                
		}()        
	}        
	wg.Wait()        
	close(errChan)       
	return 
}
```
The solution to this problem is to move sem <- 1 inside the goroutine.
Now all the fetch goroutines will be created immediately, and will negotiate a semaphore when they get scheduled by the runtime.
And this leads to my next recommendation

- 这种解决方式是，移动`sem <- 1` 到goroutine里。现在，所有fetch的goroutine将会立刻启动，并且在他们runtime被调度时，会协商一个信号量，这引出我的下一个建议。

Acquire semaphores when you’re ready to use them.Although goroutines are cheap to create and schedule, the resources they operate on, files, sockets,bandwidth, and so on, are often scarcer. The pattern of using a channel as a semaphore to limit work in progress is quite common. However, to make sure that you don’t unduly block the code offloading work to a goroutine, acquire a semaphore when you’re ready to use them, not when you expect to use them

- 当你准备使用获取的信号量时，虽然goroutines创建、调度起来非常廉价，他们操作的资源、文件、sockets、带宽等等，通常是比较匮乏的，使用一个channel作为信号量的模式，去限制进程中的任务是非常常见的，无论怎样，当你准备去使用channel时，确保你不会过渡的阻塞信号量，而不是你希望使用channel时。

Hopefully we’ve got all the bugs 
out of this program
 ...
Hopefully we’ve got all the bugs out of this program.
But there’s one more obvious one that we haven’t talked about yet. And it’s a serious one that catches almost every Go programmer out at least once

- 希望我们现在都找到这段程序的bug了。但是有个更明显的问题我们还没有讨论到。这个更严重的问题，几乎每个gopher都至少遇到过一次。

```
func restore(repos []string) error {
        errChan := make(chan error, 1)
        sem := make(chan int, 4) // four jobs at once
        var wg sync.WaitGroup
        wg.Add(len(repos))
        for _, repo := range repos {
                go func() {
                        defer wg.Done()
                        sem <- 1
                        if err := fetch(repo); err != nil {
                                errChan <- err
                        }
                        <-sem
                }()
        }
        wg.Wait()
        close(errChan)
        return <-errChan
}
```

The variable repo in the for loop is lexically captured by the anonymous function executed as a goroutine.
click / click
This is going to lead to two problems:
1.The value of repo inside the goroutine is going to be overwritten on each loop iteration; all the fetch calls will likely end up trying to fetch the last repository.
2.This is a data race because we have one goroutine assigning to repo concurrently with others are trying to read it

- for循环中的repo变量获取，是通过goroutine中执行的匿名函数获取的。这将会引起两个问题:1,goroutine内部repo的值，将会在每次遍历时，被覆盖，所有的fetch调用将很可能都去fetch最后一个repo值对应的仓库；2，这是所谓的“竞态数据”，因为我们只有有一个主goroutine给每次遍历的的repo复制，但是其他的子goroutines都在读取repo的值。

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for i := range repos {
		go func() {
			defer wg.Done()
			sem <- 1
			if err := fetch(repos[i]); err != nil {
				errChan <- err
			}
			<-sem
		}()
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
```

This is one of the classical Go paper cuts which all of us have to learn the hard way. You might think that rewriting the program to use an index variable would solve it。But in fact this is just a different version of the same problem; rather than capturing repo lexically, each goroutine captures the variable i.In my opinion, the cause of this common error is the interaction between anonymous functions, lexical closures, and goroutines.It’s cute to be able to write an anonymous function and execute it inline with a goroutine, but the reader has to consider the effects of lexical closure, and we know that the ideas of nested scopes are already a pain point for many developers no matter their level of experience.

- 这是经典的go论文中截取出来的一部分，我们都要学习的。你可能会认为，写这段代码时使用一个索引变量将会解决上面的问题，但是实际上，这仅仅是同样问题的另一种展现形式： 相比较在迭代中捕获repo，这是在每个goroutine中捕获了变量i。我认为，这些同样错误的原因是匿名函数、闭包语法、goroutine之间的交互导致的。很聪明，写能出一个匿名函数并且能在goroutine里解决执行它，但是读者不得不Kelvin闭包语法的影响，我们知道嵌套作用域已经成为很多开发者的痛点，无论他们的经验如何。

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for i := range repos {
		go func(repo string) {
			defer wg.Done()
			sem <- 1
			if err := fetch(repo); err != nil {
				errChan <- err
			}
			<-sem
		}(repos[i])
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
```
Instead what we must do is ensure that unique values of repo (or i) are passed to each fetch goroutine as they are invoked. There are a few ways to do this, but the most obvious is to explicitly pass the repo value into our goroutine.

- 相反的，我们必须要做的是，确保在调用goroutines时，传递给每个fetch的变量：repo（或者i）的值是唯一的。有几种方法可以做到，但是最显而易见的方式是“显式的传递repo值给goroutine”。

The recommendation I draw from this is，Avoid mixing anonymous functions and goroutines

- 所我的建议是：`避免把goroutine与匿名方法混合到一起`

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {

	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}
```

To apply my own advice, we replace the anonymous function with a named one, and pass all the variables necessary to it.This results in a less pithy example, but in return it eliminates the possibility of lexical capture, and the associated data race

- 为了使用我的建议，我们用实名函数替换掉匿名函数，并且传递给它所需要的变量。结果是上述例子变成了一个不太精简的示例，但是作为回报，它消除了语法上的歧义和“有相关性的竞态数据”。


So now, after this review we’ve refactored the code to make a clean separation between producing work to be performed—our restore function—from the execution of that work—the worker function.Have we fixed all the issues with this code? Not yet, there’s still one left.

- 到目前为止，这次代码的审查后，我们重构了程序：在需要执行的producing方法、worker方法之间，我们做了一个整洁的代码分离。我们解决了所有的问题吗？还没，还有一个。

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}
```
Let’s look at the core of the worker function, calling fetch and handling the error.Can anyone see a problem with this? I’ll give you a hint; what happens if more than one fetch fails, say if the network goes down and all the fetches fail at once. What would happen?

- 我们看下这个worker方法的核心内容，调用fetch、获取错误。有咩有谁能看出这里的问题？我给你们一个提示：如果多个fetch失败，会发生什么？如果网络断掉所有的fetch都失败了，会发生什么？

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}
```

Let’s have a look at the declaration of errChan.It’s a buffered channel with a capacity of one. But our semaphore channel has a capacity of four, so potentially we could have up to four goroutines trying to write errors to errChan. errChan won’t be read from until wg.Wait returns, and wg.Wait will not return until wg.Done has been called in each goroutine. So we have a potential deadlock situation.And to resolve this, I want to introduce my last piece of advice

- 我们来看下errChan的定义，这是带有一个容量的缓冲channel，但是我们的信号channel，有四个缓冲，所以潜在的情况是，我们最多会有四个goroutine都失败都往errChan里写如错误。errChan不会去取出内容，知道sg.Wait返回，并且wg.Wait将不会返回内容知道wg.Done在每个goroutine里被调用完成。所以我们有一个潜在的思索场景，并且为了去解决这个问题，我想介绍一下我的建议的最后一部分。

Before you start a groutine, always know when and how it will stop.How to we go about applying this advice? I like to work backwards and ask what are the ways this goroutine can exit. We know the goroutine starts at the worker function, so when worker exits the goroutine is done.

- 在你开始一个goroutine之前，一定要了解什么时候停止、如何停止。这个建议我们如何应用呢？我喜欢逆向思维，并提问goroutine退出的方式是什么。我们知道goroutine在worker方法前开始，所以当worker退出时，gotoutine就完成了。

```
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}
```
Because this function contains a defer statement we consider this statement last. If there were multiple defer statements they are executed Last in, first out。wg.Done is a signal the waitgroup—another kind of semaphore—that the task is done. wg.Done never blocks so this statement will not prevent worker returning.


- 因为这个方法包含一个defer声明，我们最后考虑这个声明。如果最后有多个被执行的defer声明，他们以 `先进后出`的方式执行，wg.Done另外一种信号量，是等待组中的任务完成的信号。wg.Done永远不会阻塞，所以这个声明将不会阻止worker方法的返回。
```
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}

```
The penultimate statement is the receive from <-sem, which cannot block because we could not have got to this point without placing a value into sem. The value we get out may not be the one we placed there, but we are guaranteed to receive a value, so that statement won’t block.

- 倒数第二个语法：`<-sem`，是从channel类型sem中取出数据，这个是不能阻塞的，因为我们不可能到这一步，而不给他赋值。我们取出的这个值，可能不是我们赋值进去的那一个，但是我们保证可以取出一个值，以便于语法不会阻塞

This just leaves the call to fetch which we assume has appropriate timeouts in place to handle badly behaved remote servers.If there is no error from fetch the function will return, passing through defer as we saw earlier and the goroutine is done. However if there is an error, then we must first place it onto the errChan channel.If want to make sure all possible writes to errChan do not block, what’s the right capacity for errChan?

- 这仅仅是把调用留给了fetch，我们假设在处理表现得糟糕的远程服务器时，有合适的超时机制。如果fetch方法没有错误，它将会返回，通过我们之前看到的defer声明，然后gorouotine结束，无论怎样，如果有一个错误，然后我们必须首先把它赋值给channel类型的errChan变量，如果我们试图确保所有可能给errChan写数据的操作不会被阻塞，那么errChan是最合适的容量是多少呢？

```
func restore(repos []string) error {
	errChan := make(chan error, len(repos))
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}

func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		errChan <- err
	}
	<-sem
}
```
One answer would be to set the capacity of errChan to the size of len(repos).This guarantees that even if every fetch were to fail, there will be capacity to store each error without blocking the send.However there is another option. restore only returns one error value, which it reads from errChan.

- 有一个答案是，将errChan的容量设置为len(repos)（repos的长度）。这个确保了当每个fetch失败的时候，有足够的容量去存储每个错误，而不会阻塞。然而，还有另外一个选项：只返回一个错误值，这个值是从errChan里读取的。

```

func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
func worker(repo string, sem chan int, wg *sync.WorkGroup, errChan chan err) {
	defer wg.Done()
	sem <- 1
	if err := fetch(repo); err != nil {
		select {
		case errChan <- err:
		// were the first worker to fail
		default:
			// some other failure has already happened
		}
	}
	<-sem
}
```
Rather than creating space for all possible errors, we can use a non blocking send to place the error onto errChan if non already exists, otherwise the value is discarded.

- 相对于 “为所有可能的错误创造空间”，我更倾向于创建一个非阻塞的方式，去把error赋值给channel类型的errChan变量。

```
func restore(repos []string) error {
	errChan := make(chan error, 1)
	sem := make(chan int, 4) // four jobs at once
	var wg sync.WaitGroup
	wg.Add(len(repos))
	for _, repo := range repos {
		go worker(repo, sem, wg, errChan)
	}
	wg.Wait()
	close(errChan)
	return <-errChan
}
```

As a bonus question, which you can come and talk to me about afterwards. The read from errChan in restore is guaranteed to never block, even if all calls to fetch succeeded. How does this work?

- 额外的一个“关于之后”的问题，从 恢复中的errChan读取，可以保证永不阻塞，即使所有的fetch操作都成功了。这是如何实现的呢